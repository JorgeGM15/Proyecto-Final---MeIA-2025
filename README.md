
# **An√°lisis de Sentimientos en Rese√±as de Pueblos M√°gicos - Reto MeIA 2025**

Este repositorio contiene la soluci√≥n para el reto de **An√°lisis de Sentimientos en Pueblos M√°gicos Mexicanos** del Macroentrenamiento en Inteligencia Artificial (MeIA) 2025. El objetivo es clasificar la polaridad de rese√±as tur√≠sticas en una escala del 1 (muy negativo) al 5 (muy positivo) utilizando un modelo de lenguaje basado en Transformers[cite: 1].

-----

## **Descripci√≥n General** üìú

El proyecto implementa un flujo de trabajo de Procesamiento de Lenguaje Natural (PLN) para realizar an√°lisis de sentimientos. Se utiliza un modelo **BERT pre-entrenado para espa√±ol**, que es ajustado (fine-tuned) con un conjunto de datos espec√≠fico de rese√±as de Pueblos M√°gicos. Finalmente, el modelo entrenado se usa para predecir la polaridad de nuevas rese√±as no etiquetadas[cite: 1].

### **Tecnolog√≠as y Modelos** ü§ñ

  * **Modelo Base**: `dccuchile/bert-base-spanish-wwm-cased`, un modelo de la arquitectura BERT optimizado para el espa√±ol.
  * **Librer√≠as Principales**: `Transformers` de Hugging Face, `datasets`, `PyTorch`, `pandas` y `scikit-learn`.

-----

## **Estructura del Proyecto** üìÇ

```
.
‚îú‚îÄ‚îÄ datos/
‚îÇ   ‚îú‚îÄ‚îÄ MeIA_2025_train.xlsx
‚îÇ   ‚îî‚îÄ‚îÄ MeIA_2025_test_wo_labels.xlsx
‚îú‚îÄ‚îÄ resultados/
‚îÇ   ‚îî‚îÄ‚îÄ MEIAbot-2.txt
‚îî‚îÄ‚îÄ modelo2.py
```

  * **`datos/`**: Contiene los archivos de datos proporcionados para el reto.
      * `MeIA_2025_train.xlsx`: **5,000 rese√±as etiquetadas** para entrenamiento y validaci√≥n.
      * `MeIA_2025_test_wo_labels.xlsx`: **2,500 rese√±as sin etiquetar** para la predicci√≥n final.
  * **`modelo2.py`**: El script principal que contiene toda la l√≥gica para cargar datos, entrenar el modelo y generar las predicciones.
  * **`resultados/`**: Carpeta donde se guarda el archivo final con las predicciones.
      * `MEIAbot-2.txt`: El archivo de salida generado por el script, con las predicciones en el formato requerido.

-----

## **Funcionamiento del C√≥digo (`modelo2.py`)** ‚öôÔ∏è

El script `modelo2.py` automatiza el proceso completo en cuatro pasos principales:

### **Paso 1: Carga y Preparaci√≥n de Datos**

1.  **Carga de Datos**: Se leen los archivos `MeIA_2025_train.xlsx` y `MeIA_2025_test_wo_labels.xlsx` usando la librer√≠a `pandas`.
2.  **Limpieza y Mapeo**:
      * Se eliminan las columnas de metadatos (`Town`, `Region`, `Type`), ya que el modelo se centrar√° exclusivamente en el contenido textual de la rese√±a.
      * La columna `Review` se renombra a `texto` y `Polarity` a `labels` para compatibilidad con las librer√≠as de Hugging Face.
      * **Paso Cr√≠tico**: Las etiquetas de polaridad (1 a 5) se transforman a un rango de **0 a 4** (`labels - 1`), ya que los modelos de clasificaci√≥n requieren √≠ndices que comiencen en cero.
3.  **Divisi√≥n del Conjunto**: El conjunto de datos etiquetado se divide en un **80% para entrenamiento** y un **20% para validaci√≥n**. La divisi√≥n estratificada (`stratify`) asegura que la proporci√≥n de cada clase de sentimiento sea la misma en ambos conjuntos.
4.  **Conversi√≥n a `Dataset`**: Los DataFrames de `pandas` se convierten a objetos `Dataset` de la librer√≠a de Hugging Face para optimizar el manejo de memoria y el rendimiento.

### **Paso 2: Tokenizaci√≥n**

1.  **Carga del Tokenizador**: Se carga el tokenizador correspondiente al modelo `dccuchile/bert-base-spanish-wwm-cased`.
2.  **Funci√≥n de Tokenizaci√≥n**: Se define una funci√≥n que toma el texto de las rese√±as y lo convierte en un formato num√©rico que el modelo BERT puede entender. Cada texto se **trunca o rellena** para tener una longitud fija de **128 tokens**.
3.  **Aplicaci√≥n**: Esta funci√≥n se aplica a todos los conjuntos de datos (entrenamiento, validaci√≥n y el de prueba sin etiquetas).

### **Paso 3: Configuraci√≥n y Fine-Tuning del Modelo**

1.  **Carga del Modelo**: Se carga el modelo `AutoModelForSequenceClassification` a partir del checkpoint `dccuchile/bert-base-spanish-wwm-cased` y se configura para una tarea de clasificaci√≥n con **5 etiquetas** (de 0 a 4).
2.  **Argumentos de Entrenamiento**: Se definen los hiperpar√°metros del entrenamiento a trav√©s de `TrainingArguments`. Los m√°s importantes son:
      * `num_train_epochs=5`: El modelo procesar√° todo el conjunto de entrenamiento 5 veces.
      * `per_device_train_batch_size=8`: Se entrenar√° en lotes de 8 rese√±as a la vez.
      * `eval_strategy="epoch"`: El rendimiento del modelo se medir√° contra el conjunto de validaci√≥n al final de cada √©poca.
      * `load_best_model_at_end=True`: Al finalizar, se cargar√° autom√°ticamente el checkpoint del modelo que obtuvo los mejores resultados en la validaci√≥n.
3.  **M√©tricas de Evaluaci√≥n**: Se define una funci√≥n (`compute_metrics`) para calcular la precisi√≥n (`accuracy`), F1-Score, `precision` y `recall` durante la fase de validaci√≥n.
4.  **Entrenamiento**: Se inicializa el `Trainer` con el modelo, los datos y los argumentos, y se ejecuta el m√©todo `trainer.train()` para comenzar el proceso de fine-tuning.

### **Paso 4: Predicci√≥n y Generaci√≥n de Resultados**

1.  **Predicci√≥n**: Una vez entrenado, el modelo se utiliza para predecir la polaridad del conjunto de datos sin etiquetar (`MeIA_2025_test_wo_labels.xlsx`).
2.  **Procesamiento de Salida**: El modelo devuelve "logits" (valores num√©ricos) para cada clase. Se aplica la funci√≥n `argmax` para determinar la clase con la puntuaci√≥n m√°s alta, que corresponde a la etiqueta predicha (0 a 4).
3.  **Generaci√≥n del Archivo Final**:
      * Las predicciones se a√±aden como una nueva columna al DataFrame de los datos sin etiquetar.
      * Se genera el archivo de salida, por ejemplo `MEIAbot-2.txt`. En este archivo, a cada predicci√≥n se le suma 1 para **convertirla de nuevo a la escala original de 1 a 5**, cumpliendo con el formato `MeIA {ID} {Polaridad}`.

-----

## **C√≥mo Ejecutar el Proyecto** ‚ñ∂Ô∏è

1.  **Instalar dependencias**:
    ```bash
    pip install pandas openpyxl torch transformers datasets scikit-learn
    ```
2.  **Organizar los archivos**: Aseg√∫rate de que los archivos `.xlsx` est√©n en la carpeta correcta (`/datos/` o la ruta especificada en el script).
3.  **Ejecutar el script**:
    ```bash
    python modelo2.py
    ```
4.  **Verificar la salida**: El archivo con las predicciones se generar√° en la ruta de salida especificada dentro del script (ej. `/resultados/`).
